# -*- coding: utf-8 -*-
"""KDM_ICP12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1boi-hY6trFMmWD0QHEo3rUQzL3_nWEIk
"""

import numpy as np
import math
import pandas as pd
import matplotlib.pyplot as plt

from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

"""**Prediction: using the number of passengers (in units of thousands) this month, what is the number of passengers next month?**

We can write a simple function to convert our single column of data into a two-column dataset: the first column containing this month’s (t) passenger count and the second column containing next month’s (t+1) passenger count, to be predicted.
"""

Data = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv')

Data.columns

"""We are not interested in the date, given that each observation is separated by the same interval of one month. Therefore, when we load the dataset we can exclude the first column."""

New_Data = Data['Passengers']

New_Data = np.array(New_Data).reshape(-1,1)

plt.plot(New_Data)

"""LSTMs are sensitive to the scale of the input data, specifically when the sigmoid (default) or tanh activation functions are used. It can be a good practice to rescale the data to the range of 0-to-1, also called normalizing. We can easily normalize the dataset using the MinMaxScaler preprocessing class from the scikit-learn library."""

scaler = MinMaxScaler()
New_Data = scaler.fit_transform(New_Data)
print(New_Data)

New_Data.shape

"""With time series data, the sequence of values is important. A simple method that we can use is to split the ordered dataset into train and test datasets."""

train_size = 120
test_size = 24

train = New_Data[:train_size]
train.shape

test = New_Data[train_size:144]
test.shape

"""We can write a simple function to convert our single column of data into a two-column dataset: the first column containing this month’s (t) passenger count and the second column containing next month’s (t+1) passenger count, to be predicted."""

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return np.array(dataX), np.array(dataY)

look_back = 1
X_train, y_train = create_dataset(train, look_back)

print(X_train.shape)
print(y_train.shape)

look_back = 1
X_test, y_test = create_dataset(test, look_back)

print(X_test.shape)
print(y_test.shape)

X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)
print("New training data shape:", X_train.shape)
print("New testing data shape:", X_test.shape)

"""Now, Build a simple LSTM model on training data. The LSTM architecture here consists of:
1.   One input layer.
2.   Two LSTM layer of 4 blocks.
3.   Dropout values
4.   One Dense layer to produce a single output.
5.   Use MSE as loss function
"""

model = Sequential()
model.add(LSTM(4,input_shape = (1, look_back),return_sequences=True))
model.add(Dropout(0.5))
model.add(LSTM(4))
model.add(Dropout(0.5))
model.add(Dense(1))
model.compile(loss = "mean_squared_error", optimizer = "adam")

model.summary()

model.fit(X_train, y_train, epochs = 100, batch_size = 10)

trainPredict = model.predict(X_train)
testPredict = model.predict(X_test)

trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([y_train])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([y_test])

trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Training Data Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Testing Data Score: %.2f RMSE' % (testScore))

# Start with training predictions.
train_predict_plot = np.empty_like(New_Data)
train_predict_plot[:, :] = np.nan
train_predict_plot[look_back:len(trainPredict) + look_back, :] = trainPredict

# Add test predictions.
test_predict_plot = np.empty_like(New_Data)
test_predict_plot[:, :] = np.nan
test_predict_plot[len(trainPredict) + (look_back * 2) + 1:len(New_Data) - 1, :] = testPredict

plt.figure(figsize = (10, 5))
plt.plot(scaler.inverse_transform(New_Data), label = "True value")

plt.plot(train_predict_plot, label = "Training set prediction")
plt.plot(test_predict_plot, label = "Test set prediction")

plt.xlabel("Months")
plt.ylabel("1000 International Airline Passengers")
plt.title("Comparison true vs. predicted training / test")
plt.legend()
plt.show()